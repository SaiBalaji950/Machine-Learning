{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf969f8-08b3-4579-b0db-fb69dbd7da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression\n",
    "\n",
    "Regreesion algorithm is used to find the relationships between input variables and output variables. it is used for the prediction of continuous \n",
    "variable like Weather Forecast and stock market trades etc.\n",
    "\n",
    "Regression algorithms are:\n",
    "1) Linear Regression\n",
    "2) Non-Linear Regression\n",
    "3) Bayesian Linear Regression\n",
    "4) Polynomial Regression\n",
    "5) Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4f5f7-9e1a-4fb3-9fec-7753f2843ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overfitting\n",
    "\n",
    "This happens when the machine learning model learns the training data too well, capturing noise and dont generalize the new data.\n",
    "the model performs well on training data but poorly on unseen data.\n",
    "\n",
    "Simply Overfitting means too complex model, fits training data too closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7b76b-17b4-4f7a-bc0c-6e9025b692a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting\n",
    "\n",
    "This occurs when the model is too simple to capture the underlying patterns in the data.\n",
    "But it performs poorly on both training and new data because it hasn't learned enough from the training data.\n",
    "\n",
    "Simply Underfitting means too simple model, but fails to capture the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf166b-db81-46b1-b35b-b05fe559bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Terminilogies Related to Regression Analysis\n",
    "\n",
    "1) Dependent Variables\n",
    "2) Independent Variables\n",
    "3) Outliers\n",
    "4) Multicollinearity\n",
    "5) Overfitting\n",
    "6) Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a942d-1c56-4faa-a7ab-ed999ad2b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dependent Variables\n",
    "\n",
    "The Main factor in the Regression which we want to predict or understand is called Dependent variable. \n",
    "This is also called the Target Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52d8e5-c52c-48b1-b844-70c987a6145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Independent Variables\n",
    "\n",
    "The Factors which may effect the Dependent variables or which are used to predict the values is called Independent Variables.\n",
    "This is also called Predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76f3a8-19d5-4ab2-a187-42cf47efb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers\n",
    "\n",
    "An Outlier is an observation which contains either very low value or very high value in comparision to other observed values.\n",
    "An Outlier may hamper the result. so an outlier was avoided.\n",
    "\n",
    "Here Hamper means very danger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7902b-e8e6-4918-8c6b-c4034c018bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multicollinearity\n",
    "\n",
    "If the independent variables are highly co-related with each other than variables, such the condition is called Multicollinearity.\n",
    "But Multicollinearity is not present in the dataset because while in the ranking the most affecting variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d83b23-7cd9-4932-8953-f150511058d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overfitting\n",
    "\n",
    "If our Algorithm works well with the training dataset but not performs well in the test dataset, then the problem is called Overfitting.\n",
    "\n",
    "This happens when the machine learning model learns the training data too well, capturing noise and don't generalize the new data.\n",
    "But it performs well both training data and new data but performs poorly on unseen data\n",
    "\n",
    "Simply Overfitting means too complex model, fits on training data too closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c12a9-c830-4f16-b006-a1b46093a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting\n",
    "\n",
    "If our Algorithm not works well even with the training dataset then the problem is called Underfitting.\n",
    "\n",
    "This Occurs when the model is too simple to find the underlying patterns in the data.\n",
    "But it Performs poorly on both Training data and new data because it hasn't learned even from the training data.\n",
    "\n",
    "Simply Underfitting means too simple model, but fails to capture the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833c275-0bc2-4f6d-9392-aff3f1d62377",
   "metadata": {},
   "outputs": [],
   "source": [
    "why do we use Regression Analysis ?\n",
    "\n",
    "1) Regression Estimates the relationship between the target(Dependent variable) and predictor(Independent variable).\n",
    "2) it is used to find the trends in data\n",
    "3) it hepls to predict real/continuous values.\n",
    "4) By Performing Regression, we can confidently determine the most important factor,the least important factor and how each factor may\n",
    "    affect to other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb16305-69ec-4271-9184-06e89dd425f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Types of Regreesion\n",
    "\n",
    "1) Linear Regression\n",
    "2) Logistic Regression\n",
    "3) Polynomial Regression\n",
    "4) Support Vector Regression\n",
    "5) Random Forests Regression\n",
    "6) Decision Tree Regression\n",
    "7) Ridge Regression\n",
    "8) Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb6c83-75c7-4327-a023-7804fdb8fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression\n",
    "\n",
    "1) Linear Regression is a statistical Linear Regression which is used for predictive analysis.\n",
    "2) it is one of the simple and easy algorithm and shows relationship between the continuous variables.\n",
    "3) it is used for solving the regression problem in the machine learning.\n",
    "4) Linear Regression shows the linear relationship between the independent variables(X) and dependent variables(Y), Hence it is called Linear \n",
    "    Regression.\n",
    "5) If there is only one input variable is called Simple Linear Regression. If there is more than one input variable is called Multiple\n",
    "    Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40426af-5716-4994-9ab0-a035faa764f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Below is the Mathematical Equation for Linear Regression\n",
    "\n",
    "Y=aX+b\n",
    "Here, Y=Dependent Variables,\n",
    "      X=Independent Variables,\n",
    "      a and b are linear Co-efficients.\n",
    "\n",
    "Linear Regression Applications:\n",
    "1) Analyzing trades and sales estimates.\n",
    "2) Salary forecating\n",
    "3) Real estate prediction\n",
    "4) Arriving at ETA's in public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8f70b-8e32-4d80-b1dd-aea4f5a06549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression\n",
    "\n",
    "1) Logistic Regression is one of the supervised algorithm which is used for the classification Problems. In Classification Problems, \n",
    "    we have dependent variables in a binary or discrete format like 0 or 1.\n",
    "2) logistic regression algorithm works with categorical variables like 0 or 1, True or False, Yes or No, spam or not spam.\n",
    "3) It is a predictive analysis algorithm which works on the concept of probability.\n",
    "4) Logistic Regression is a type of regression, but it is different from the linear regression algorithm how the term is used.\n",
    "5) Logistic Regression uses sigmoid function or logistic function which is a complex cost function. This Sigmoid function \n",
    "     is used to model the data in logistic regression.\n",
    "\n",
    "The Function will be used as:\n",
    "f(x)=1/(1+e^(-x))\n",
    "\n",
    "Here,f(x)=output between 0 and 1 value,\n",
    "     x=input of the variable\n",
    "     y=base of neutral algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265602dd-48c8-41f7-8576-42a00fa15a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are three types of Logistic Regression:\n",
    "\n",
    "1) Binary(0/1,pass/fail)\n",
    "2) Multi(cats,dogs,Lions)\n",
    "3) Ordinal(low,medium,high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74398720-b179-4477-989e-cea2ce0adbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial Regression\n",
    "\n",
    "The equation for polynomial regression also derived from linear regression equation that means Linear regression equation \n",
    "Y= b0+ b1x, is transformed into Polynomial regression equation Y= b0+b1x+ b2x2+ b3x3+.....+ bnxn.\n",
    "Here Y is the predicted/target output, b0, b1,... bn are the regression coefficients. x is our independent/input variable.\n",
    "The model is still linear as the coefficients are still linear with quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f8771-29c9-47c9-92e2-74bc84764974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression in Machine Learning\n",
    "\n",
    "1) Linear Regression is a statistical Regression which is used for predictive analysis.\n",
    "2) it is one of the simple and easy algorithm and shows the relationship between continuous varibles.\n",
    "3) It solves the Regression Problems in Machine Learning.\n",
    "4) it shows the linear relationship between Independent variables(X) and Dependent variables(Y), Hence called Linear Regression.\n",
    "5) if there is only one variable then it is called Simple Linear Regression and if there is more than one variable then it is called Multiple \n",
    "    Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ef658-509f-49f7-bc72-8831b84b6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mathematically we present Linear Regression like this also:\n",
    "y= a0+a1x+ ε\n",
    "Here Y=Dependent Variable,\n",
    "     X=Independent Variable,\n",
    "     a0=intercept of the line(Give an additional degree of freedom)\n",
    "     a1=Linear Regression coefficient(Scale factor to each input value)\n",
    "      ε=random error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114fb36-d2b2-45cd-a0e5-de6d6e3c9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Types of Linear Regression\n",
    "\n",
    "1) Simple Linear Regression:-\n",
    "   ----------------------------\n",
    "    If there is only one input variable is called Simple Linear Regression.\n",
    "\n",
    "2) Multiple Linear Regression:-\n",
    "   ---------------------------\n",
    "    If there is more than one variable then it is called Multiple Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa85faa-af2d-445c-a79f-4612271c08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression Line\n",
    "\n",
    "A linear line showing the relationships between dependent and independent variables is known as Regression Line.\n",
    "A regression line can show two types of the relationship.they are:\n",
    "\n",
    "1) Positive Linear Relationship\n",
    "2) Negative Linear Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b4f5-d911-4b74-af74-468000858fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive Linear Relationship\n",
    "\n",
    "If the Dependent variable increases on Y-axis and independent variable increases on X-axis is called Positive Linear Relationship.\n",
    "\n",
    "it represents as Y=a0+a1X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b82ae-e1e3-4a60-b431-f19a499899e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative Linear Relationship\n",
    "\n",
    "If the Dependent variable decreases on Y-axis and independent variable increases on X-axis is called Negative Linear Relationship.\n",
    "\n",
    "it represents as Y=-a0+a1X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ec7a8-9b35-4c8c-8517-3b57b33a6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost Function\n",
    "\n",
    "Cost Function is a mathematical function which is used to measure the differences between predicted values of the model and the actual\n",
    "values from the data. it quantifies how long the model predictions are. \n",
    "The Purpose of a cost function is gives us a single number and the cost function tells how well or poorly our model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754fb39-54aa-43fd-8a44-9b3d96f6c26d",
   "metadata": {},
   "source": [
    "Cost Function in Linear Regression\n",
    "\n",
    "For Linear Regression we use Cost Function, Mean Squared Error(MSE).\n",
    "\n",
    "MSE means which is calculated the average between actual and predicted values.\n",
    "\n",
    "             m\n",
    "MSE=(1*(1/N) ∑ (yi-(a1xi+a0))^2\n",
    "             i=1\n",
    "\n",
    "N=Total Number of observations\n",
    "yi=Actual values\n",
    "(a1xi+a0)=Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d542672-3f0f-4d55-b584-7feb035d6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient Descent\n",
    "\n",
    "Gradient Descent is used to minimize the cost function MSE by calculating the gradient of cost function. it is also known as the optimizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f42bc-8bed-49f9-bb67-45295c0fdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "For Model Performance we use R-Squared Error.\n",
    "\n",
    "R-squared is a statistical method that determines the goodness of fit.\n",
    "It measures the strength of the relationship between the dependent and independent variables on a scale of 0-100%.\n",
    "The high value of R-square determines the less difference between the predicted values and actual values and hence represents a good model.\n",
    "\n",
    "R-Squared=(Explained variation/Total variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91e152-4334-404f-a690-f06aa3ca9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assumptions of Linear Regression\n",
    "\n",
    "1) Linearity\n",
    "2) Independence\n",
    "3) Homoscedasticity - Error term is same for all the independent variables.\n",
    "4) Normality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
